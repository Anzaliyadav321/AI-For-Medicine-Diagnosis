In this very exciting lesson, you'll learn how you
can train and evaluate your segmentation model for identifying tumors in MRI data. You will learn about the
UNet architecture and the procedure that we can use to successfully train a
segmentation model. As you'll quickly see, working with 3D
medical data provides some significant challenges
and you'll learn about some creative
ideas to tackle them. We'll first start by talking
about representing MRI data. We want to be able to
represent the MRI data in a form that we can input
into the segmentation model. As you've seen, our
MRI images are not just a single 2D
image like X-rays, and MRI sequence is a 3D volume here seen
in the axial view. Furthermore, an MRI example will be made up of multiple sequences, and thus will consist
of multiple 3D volumes. We'll look at how we can combine these multiple 3D volumes
into one 3D volume. To do so, let's pick a
slice through the brain. This is a slice through
the brain viewed on three different MRI sequences. The key idea that we will use to combine the
information from different sequences is to treat them as different channels. We can say one of the channels
is red, one is green, and one is a blue channel
in the same way that we have three channels
of an RGB image. The analogy of the three channels representing the RGB channels is mostly useful for us to visualize how we're going
to combine the channels. There's nothing special
about the number three. The idea of using
different channels also extends to when we may have
four or five sequences, which can be represented
with four or five channels. Once each sequence is represented with the
different channel, what we do now is combine the sequences together
to produce one image, which is the combination
of all of the sequences. To us, this is now an RGB image. To the machine, these are channels stacked in
the depth dimension. One challenge with combining these sequences is that they may not be aligned with each other. For instance, if a patient moves between the acquiring of
each of these sequences, their head might be tilted in one sequence compared
with the others. If the images are
not aligned with each other when we combine them, the brain region at one location in the
red channel does not correspond to the same location in the green or
the blue channels. So how do we fix this
alignment problem? A preprocessing approach
that's often used to fix this is called
image registration. The basic idea with
image registration is to transform
the images so that they're aligned or
registered to each other. We won't go into image
registration in further detail. In the assignment,
you'll work with images that have already
been registered. However, it is useful
to be aware of image registration
as a useful tool when trying to combine 3D volumes.